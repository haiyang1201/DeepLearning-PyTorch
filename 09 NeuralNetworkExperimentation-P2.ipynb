{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Run PyTorch Code On A GPU - Neural Network Programming Guide\n",
    "\n",
    "**In this episode, we're going to learn how to use the GPU with PyTorch. We'll see how to use the GPU in general, and we'll see how to apply these general techniques to training our neural network.**\n",
    "\n",
    "## Using A GPU For Deep Learning\n",
    "### PyTorch GPU Example\n",
    "PyTorch allows us to seamlessly move data to and from our GPU as we preform computations inside our programs.\n",
    "\n",
    "When we go to the GPU, we can use the `cuda()` method, and when we go to the CPU, we can use the `cpu()` method.\n",
    "\n",
    "We can also use the `to()` method. To go to the GPU, we write `to('cuda')` and to go to the CPU, we write `to('cpu')`. The `to()` method is the preferred way mainly because it is more flexible. We'll see one example using using the first two, and then we'll default to always using the `to()` variant.\n",
    "\n",
    "| <center><b>CPU</b></center> | <center><b>GPU</b></center> |\n",
    "| --- | --- |\n",
    "| <center>`cpu()`</center> | <center>`cuda()`</center> |\n",
    "| <center>`to('cpu')`</center> | <center>`to('cuda')`</center> |\n",
    "\n",
    "To make use of our GPU during the training process, there are two essential requirements. These requirements are as follows, the **data** must be moved to the GPU, and the **network** must be moved to the GPU.\n",
    "1. Data on the GPU\n",
    "2. Network on the GPU\n",
    "\n",
    "By default, when a PyTorch tensor or a PyTorch neural network module is created, the corresponding data is initialized on the **CPU**. Specifically, the **data** exists inside the CPU's memory.\n",
    "\n",
    "Now, let's create a tensor and a network, and see how we make the move from CPU to GPU.\n",
    "\n",
    "Here, we create a tensor and a network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x217323b7d60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import product\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "torch.set_printoptions(linewidth=120)  # Display options for output\n",
    "torch.set_grad_enabled(True)  # Already on by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t\n",
    "\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t,  kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = t.reshape(-1,12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(1,1,28,28)\n",
    "network = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we call the `cuda()` method and reassign the tensor and network to returned values that have been copied onto the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.cuda()\n",
    "network = network.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can get a prediction from the network and see that the prediction tensor's device attribute confirms that the data is on cuda, which is the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_pred = network(t)\n",
    "gpu_pred.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we can go in the **opposite** way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.cpu()\n",
    "network = network.cpu()\n",
    "\n",
    "cpu_pred = network(t)\n",
    "cpu_pred.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is, in a nutshell, how we can utilize the GPU capabilities of PyTorch. What we should turn to now are some important details that are lurking beneath the surface of the code we've just seen.\n",
    "\n",
    "For example, although we've used the `cuda()` and `cpu(`) methods, they actually **aren't our best options**. Furthermore, what's the difference with the methods between the **network instance** and the **tensor instance**? These after all are different objects types, which means the two methods are different. Finally, we want to integrate this code into a working example and do a performance test.\n",
    "\n",
    "### General Idea Of Using A GPU\n",
    "The **main takeaway** at this point is that our **network** and our **data** must **both exist on the GPU** in order to perform computations using the GPU, and this applies to any programming language or framework.\n",
    "![CPUGPU](https://deeplizard.com/images/gpu%20vs%20cpu.jpg)\n",
    "As we'll see in our next demonstration, this is **also true for the CPU**. GPUs and CPUs are compute devices that compute on data, and so any two values that are directly being used with one another in a computation, **must exist on the same device**.\n",
    "\n",
    "## PyTorch `Tensor` Computations On A GPU\n",
    "Let's dive deeper by demonstrating some tensor computations.\n",
    "\n",
    "We'll start by creating two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll check which **device** these tensors were **initialized** on by inspecting the device attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.device, t2.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we'd expect, we see that, indeed, both tensors are on the **same device**, which is the CPU. Let's **move** the first tensor t1 to the **GPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = t1.to('cuda')\n",
    "t1.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this tensor's device has been changed to `cuda`, the GPU. Note the use of the `to()` method here. Instead of calling a particular method to move to a device, we call the same method and pass an argument that specifies the device. Using the `to()` method is the preferred way of moving data to and from devices.\n",
    "\n",
    "Also, note the reassignment. The operation is not in-place, and so the reassignment is required.\n",
    "\n",
    "Let's try an experiment. I'd like to test what we discussed earlier by attempting to perform a computation on these **two tensors**, `t1` and `t2`, that we now know to be on **different devices**.\n",
    "\n",
    "Since we expect an error, we'll wrap the call in a `try` and `catch` the exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    t1+t2\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These errors are telling us that the binary plus operation expects the second argument to have the same device as the first argument. Understanding the meaning of this error can help when debugging these types of device mismatches.\n",
    "\n",
    "Finally, for completion, let's move the second tensor to the cuda device to see the operation succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  8],\n",
       "        [10, 12]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = t2.to('cuda')\n",
    "t1 + t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch `nn.Module` Computations On A GPU\n",
    "We've just seen how tensors can be **moved** to and from devices. Now, let's see how this is done with PyTorch `nn.Module` instances.\n",
    "\n",
    "More generally, we are interested in understanding **how** and **what** it means for a **network** to be on a device like a GPU or CPU. PyTorch aside, this is the essential issue.\n",
    "\n",
    "We put a network on a device by moving the network's parameters to that said device. Let's create a network and take a look at what we mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwtwork = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Now, let's look at the network's parameters:\n",
    "for name,param in network.named_parameters():\n",
    "    print(name,'\\t\\t',param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've created a PyTorch network, and we've iterated through the network's parameters. As we can see, the network's parameters are the **weights** and **biases** inside the network.\n",
    "\n",
    "In other words, these are simply tensors that live on a device like we have already seen. Let's verify this by checking the **device** of each of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu  conv1.weight\n",
      "cpu  conv1.bias\n",
      "cpu  conv2.weight\n",
      "cpu  conv2.bias\n",
      "cpu  fc1.weight\n",
      "cpu  fc1.bias\n",
      "cpu  fc2.weight\n",
      "cpu  fc2.bias\n",
      "cpu  out.weight\n",
      "cpu  out.bias\n"
     ]
    }
   ],
   "source": [
    "for n,p in network.named_parameters():\n",
    "    print(p.device,'',n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that all the **parameters** inside the **networ** are, by default, initialized on the **CPU**.\n",
    "\n",
    "An important consideration of this is that it explains why `nn.Module` instances like networks don't actually have a device. **It's not the *network* that lives on a device**, but the ***tensors* inside the *network* that live on a device**.\n",
    "\n",
    "Let's see what happens when we ask a network to be moved `to()` the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a **reassignment** was not required. This is because the operation is in-place as far as the network instance is concerned. However, this operation can be used as a reassignment operation. This is preferred for consistency between `nn.Module` instances and PyTorch tensors.\n",
    "\n",
    "Here, we can see that now, all the network parameters are have a device of `cuda`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0  conv1.weight\n",
      "cuda:0  conv1.bias\n",
      "cuda:0  conv2.weight\n",
      "cuda:0  conv2.bias\n",
      "cuda:0  fc1.weight\n",
      "cuda:0  fc1.bias\n",
      "cuda:0  fc2.weight\n",
      "cuda:0  fc2.bias\n",
      "cuda:0  out.weight\n",
      "cuda:0  out.bias\n"
     ]
    }
   ],
   "source": [
    "for n,p in network.named_parameters():\n",
    "    print(p.device,'',n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing A Sample To The Network\n",
    "Let's round off this demonstration by passing a **sample** to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.ones(1,1,28,28)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n"
     ]
    }
   ],
   "source": [
    "# This gives us a sample tensor we can pass like so:\n",
    "try:\n",
    "    network(sample)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our **network** is on the **GPU** and this newly created **sample** is on the **CPU** by **default**, we are getting an error. The error is telling us that the CPU tensor was expected to be a GPU tensor when calling the forward method of the first convolutional layer. This is precisely what we saw before when adding two tensors directly.\n",
    "\n",
    "We can fix this issue by sending our sample to the GPU like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0682, -0.1137,  0.0062, -0.1020, -0.1043, -0.1616,  0.0101, -0.0623, -0.1047, -0.0606]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pred = network(sample.to('cuda'))\n",
    "    print(pred)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, everything works as expected, and we get a prediction.\n",
    "### Writing Device Agnostic PyTorch Code\n",
    "Before we wrap up, we need to talk about writing device agnostic code. This term `device agnostic` means that our code **doesn't depend on the underlying device**. You may come across this terminology when reading PyTorch documentation.\n",
    "\n",
    "For example, suppose we write code that uses the `cuda()` method everywhere, and then, we give the code to a user who **doesn't have a GPU**. This won't work. Don't worry. We've got options!\n",
    "\n",
    "Remember earlier when we saw the `cuda()` and `cpu()` methods?\n",
    "\n",
    "We'll, one of the reasons that the `to()` method is preferred, is because the `to()` method is **parameterized**, and this makes it easier to **alter the device we are choosing**, i.e. it's flexible!\n",
    "\n",
    "For example, a user could pass in `cpu` or `cuda` as an argument to a deep learning program, and this would allow the program to be device agnostic.\n",
    "\n",
    "Allowing the user of a program to pass an argument that determines the program's behavior is perhaps the best way to make a program be device agnostic. However, we can also use PyTorch to check for a supported GPU, and set our devices that way.\n",
    "```python\n",
    "torch.cuda.is_available()\n",
    "True\n",
    "```\n",
    "Like, if cuda is available, then use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch GPU Training Performance Test\n",
    "Let's see now how to add the use of a **GPU** to the **training loop**. We're going to be doing this addition with the code we've been developing so far in the series.\n",
    "\n",
    "This will allow us to easily compare times, CPU vs GPU.\n",
    "\n",
    "### Refactoring The RunManager Class\n",
    "Before we update the training loop, we need to update the `RunManager` class. Inside the `begin_run()` method we need to modify the **device** of the images **tensor** that is passed to add_graph method.\n",
    "\n",
    "It should look like this:\n",
    "```python\n",
    "def begin_run(self, run, network, loader):\n",
    "    \n",
    "    self.run_start_time = time.time()\n",
    "    \n",
    "    self.run_params = run\n",
    "    self.run_count += 1\n",
    "    \n",
    "    self.network = network\n",
    "    self.loader = loader\n",
    "    self.tb = SummaryWriter(comment=f'-{run}')\n",
    "    \n",
    "    images,labels = next(iter(self.loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    \n",
    "    self.tb.add_image('images',grid)\n",
    "    self.tb.add_graph(self.network,images.to(getattr(run, 'device', 'cpu')))\n",
    "```\n",
    "\n",
    "Here, we are using the `getattr()` **built in function** to **get the value of the device** on the run object. If the run object **doesn't have a device**, then **cpu is returned**. This makes the **code backward compatible**. It will still work if we don't specify a device for our run.\n",
    "\n",
    "Note that the **network doesn't need to be moved to a device** because it's device was set before being passed in. However, the images tensor is obtained from the loader.\n",
    "\n",
    "### Refactoring The Training Loop\n",
    "We'll set our configuration parameters to have a device. The two logical options here are `cuda` and `cpu`.\n",
    "```python\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000, 10000, 20000]\n",
    "    , num_workers = [0, 1]\n",
    "    , device = ['cuda', 'cpu']\n",
    ")\n",
    "```\n",
    "With these device values added to our configuration, they'll now be available to be accessed inside our training loop.\n",
    "\n",
    "At the top of our run, we'll create a device that will be passed around inside the run and inside the training loop.\n",
    "```python\n",
    "device = torch.device(run.device)\n",
    "```\n",
    "The first place we'll use this device is when **initializing our network**.\n",
    "```python\n",
    "network = Network().to(device)\n",
    "```\n",
    "This will ensure that the network is moved to the appropriate device. Finally, we'll update our `images` and `labels` tensors by unpacking them separately and sending them to the device like so:\n",
    "```python\n",
    "images = batch[0].to(device)\n",
    "labels = batch[1].to(device)\n",
    "```\n",
    "\n",
    "**Code：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import product\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "torch.set_printoptions(linewidth=120)  # Display options for output\n",
    "torch.set_grad_enabled(True)  # Already on by default\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4,out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self,t):\n",
    "        t = t\n",
    "\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2,stride = 2)\n",
    "\n",
    "        t = t.reshape(-1,12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple('Run',params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "\n",
    "    def begin_run(self, run, network, loader):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "        images,labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images',grid)\n",
    "        self.tb.add_graph(self.network, images.to(getattr(run,'device','cpu')))\n",
    "\n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "    def end_epoch(self):\n",
    "\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss',loss,self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy',accuracy,self.epoch_count)\n",
    "\n",
    "        for name,param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name,param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad',param.grad, self.epoch_count)\n",
    "\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "        for k,v in self.run_params._asdict().items():#???\n",
    "            results[k] = v\n",
    "        self.run_data.append(results)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(self.run_data,orient='columns')\n",
    "\n",
    "    def get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "    def track_loss(self,loss,batch):\n",
    "        self.epoch_loss += loss.item() * batch[0].shape[0]\n",
    "\n",
    "    def track_num_correct(self,preds, labels):\n",
    "        self.epoch_num_correct += self.get_num_correct(preds,labels)\n",
    "\n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(self.run_data,orient='columns').to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json','w',encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',download=True,transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000,10000,20000]\n",
    "    ,num_workers = [0,1]\n",
    "    , device = ['cuda','cpu']\n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    network = Network().to(run.device)\n",
    "    loader = torch.utils.data.DataLoader(train_set,batch_size = run.batch_size)\n",
    "\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    m.begin_run(run,network,loader)\n",
    "\n",
    "    for epoch in range(2):\n",
    "\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images = batch[0].to(run.device)\n",
    "            labels = batch[1].to(run.device)\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            m.track_loss(loss,batch)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('result_GPU')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results：\n",
    "<table>\n",
    "<tr><td></td><td>run</td><td>epoch</td><td>loss</td><td>accuracy</td><td>epoch duration</td><td>run duration</td><td>lr</td><td>batch_size</td><td>num_workers</td><td>device</td></tr>\n",
    "<tr><td>0</td><td>1</td><td>1</td><td>1.028867890437444</td><td>0.61065</td><td>7.907843589782715</td><td>10.033156394958496</td><td>0.01</td><td>1000</td><td>0</td><td>cuda</td></tr>\n",
    "<tr><td>1</td><td>1</td><td>2</td><td>0.5684726412097613</td><td>0.7791833333333333</td><td>7.863961696624756</td><td>18.047714710235596</td><td>0.01</td><td>1000</td><td>0</td><td>cuda</td></tr>\n",
    "<tr><td>2</td><td>2</td><td>1</td><td>1.1850317627191544</td><td>0.5521833333333334</td><td>13.191706418991089</td><td>14.168094873428345</td><td>0.01</td><td>1000</td><td>0</td><td>cpu</td></tr>\n",
    "<tr><td>3</td><td>2</td><td>2</td><td>0.6565005630254745</td><td>0.7424166666666666</td><td>12.927437782287598</td><td>27.199254989624023</td><td>0.01</td><td>1000</td><td>0</td><td>cpu</td></tr>\n",
    "<tr><td>4</td><td>3</td><td>1</td><td>1.0353816469510397</td><td>0.5979166666666667</td><td>7.899864435195923</td><td>8.667809009552002</td><td>0.01</td><td>1000</td><td>1</td><td>cuda</td></tr>\n",
    "<tr><td>5</td><td>3</td><td>2</td><td>0.5281389872233073</td><td>0.7974833333333333</td><td>7.695444345474243</td><td>16.482932567596436</td><td>0.01</td><td>1000</td><td>1</td><td>cuda</td></tr>\n",
    "<tr><td>6</td><td>4</td><td>1</td><td>1.0003941506147385</td><td>0.6135</td><td>12.406805515289307</td><td>13.301412343978882</td><td>0.01</td><td>1000</td><td>1</td><td>cpu</td></tr>\n",
    "<tr><td>7</td><td>4</td><td>2</td><td>0.5597394168376922</td><td>0.7819333333333334</td><td>12.996736526489258</td><td>26.39090061187744</td><td>0.01</td><td>1000</td><td>1</td><td>cpu</td></tr>\n",
    "<tr><td>8</td><td>5</td><td>1</td><td>2.1817620595296225</td><td>0.21105</td><td>9.979301452636719</td><td>14.71061372756958</td><td>0.01</td><td>10000</td><td>0</td><td>cuda</td></tr>\n",
    "<tr><td>9</td><td>5</td><td>2</td><td>1.5009960730870564</td><td>0.41345</td><td>7.790157794952393</td><td>22.617460012435913</td><td>0.01</td><td>10000</td><td>0</td><td>cuda</td></tr>\n",
    "<tr><td>10</td><td>6</td><td>1</td><td>2.191338042418162</td><td>0.25776666666666664</td><td>12.654212713241577</td><td>20.27781581878662</td><td>0.01</td><td>10000</td><td>0</td><td>cpu</td></tr>\n",
    "<tr><td>11</td><td>6</td><td>2</td><td>1.5385146339734395</td><td>0.4116166666666667</td><td>13.750212907791138</td><td>34.12576651573181</td><td>0.01</td><td>10000</td><td>0</td><td>cpu</td></tr>\n",
    "<tr><td>12</td><td>7</td><td>1</td><td>2.0937188069025674</td><td>0.24205</td><td>10.781154155731201</td><td>16.329310655593872</td><td>0.01</td><td>10000</td><td>1</td><td>cuda</td></tr>\n",
    "<tr><td>13</td><td>7</td><td>2</td><td>1.6782972415288289</td><td>0.3495666666666667</td><td>8.667845487594604</td><td>25.11484146118164</td><td>0.01</td><td>10000</td><td>1</td><td>cuda</td></tr>\n",
    "<tr><td>14</td><td>8</td><td>1</td><td>2.181113620599111</td><td>0.18073333333333333</td><td>12.430742979049683</td><td>20.360525608062744</td><td>0.01</td><td>10000</td><td>1</td><td>cpu</td></tr>\n",
    "<tr><td>15</td><td>8</td><td>2</td><td>1.4258009195327759</td><td>0.4513</td><td>12.419771671295166</td><td>32.86806273460388</td><td>0.01</td><td>10000</td><td>1</td><td>cpu</td></tr>\n",
    "<tr><td>16</td><td>9</td><td>1</td><td>2.281795342763265</td><td>0.113</td><td>12.738913536071777</td><td>21.488025665283203</td><td>0.01</td><td>20000</td><td>0</td><td>cuda</td></tr>\n",
    "<tr><td>17</td><td>9</td><td>2</td><td>1.8872746229171753</td><td>0.33266666666666667</td><td>7.82509183883667</td><td>29.428784132003784</td><td>0.01</td><td>20000</td><td>0</td><td>cuda</td></tr>\n",
    "<tr><td>18</td><td>10</td><td>1</td><td>2.276853322982788</td><td>0.1421</td><td>14.396483182907104</td><td>28.404006242752075</td><td>0.01</td><td>20000</td><td>0</td><td>cpu</td></tr>\n",
    "<tr><td>19</td><td>10</td><td>2</td><td>1.9167550802230835</td><td>0.29265</td><td>13.226643323898315</td><td>41.743351221084595</td><td>0.01</td><td>20000</td><td>0</td><td>cpu</td></tr>\n",
    "<tr><td>20</td><td>11</td><td>1</td><td>2.2801879247029624</td><td>0.24583333333333332</td><td>12.877546787261963</td><td>22.319284915924072</td><td>0.01</td><td>20000</td><td>1</td><td>cuda</td></tr>\n",
    "<tr><td>21</td><td>11</td><td>2</td><td>1.8660159905751545</td><td>0.39941666666666664</td><td>7.981645345687866</td><td>30.41063666343689</td><td>0.01</td><td>20000</td><td>1</td><td>cuda</td></tr>\n",
    "<tr><td>22</td><td>12</td><td>1</td><td>2.291093111038208</td><td>0.15393333333333334</td><td>13.899812459945679</td><td>27.670968294143677</td><td>0.01</td><td>20000</td><td>1</td><td>cpu</td></tr>\n",
    "<tr><td>23</td><td>12</td><td>2</td><td>1.9686975479125977</td><td>0.35846666666666666</td><td>12.957333087921143</td><td>40.71407151222229</td><td>0.01</td><td>20000</td><td>1</td><td>cpu</td></tr>\n",
    "<tr><td></td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
